{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ma850419/Fast_UNet/blob/main/Fast_UNet_wheat_winter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a11bb28-59e4-4e50-90fe-14a707f6201f",
      "metadata": {
        "id": "6a11bb28-59e4-4e50-90fe-14a707f6201f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import concatenate\n",
        "#from test_utils import summary, comparator\n",
        "#from test_utils import  summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6a7491a-54a3-401e-a82a-b1fffee8f4a9",
      "metadata": {
        "id": "d6a7491a-54a3-401e-a82a-b1fffee8f4a9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import imageio\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "path = ''\n",
        "image_path = os.path.join(path, 'C:/samples/source_png/')\n",
        "mask_path = os.path.join(path, 'C:/samples/label_png/')\n",
        "image_list = os.listdir(image_path)\n",
        "mask_list = os.listdir(mask_path)\n",
        "image_list = [image_path+i for i in image_list]\n",
        "mask_list = [mask_path+i for i in mask_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a3d341d-6b32-4a77-8c0b-64caae83173e",
      "metadata": {
        "id": "1a3d341d-6b32-4a77-8c0b-64caae83173e"
      },
      "outputs": [],
      "source": [
        "N =130\n",
        "img = imageio.v2.imread(image_list[N])\n",
        "mask = imageio.v2.imread(mask_list[N])\n",
        "print(image_list[N],mask_list[N] )\n",
        "#mask = np.array([max(mask[i, j]) for i in range(mask.shape[0]) for j in range(mask.shape[1])]).reshape(img.shape[0], img.shape[1])\n",
        "\n",
        "fig, arr = plt.subplots(1, 2, figsize=(14, 10))\n",
        "arr[0].imshow(img)\n",
        "arr[0].set_title('Image')\n",
        "arr[1].imshow(mask[:, :])\n",
        "arr[1].set_title('Segmentation')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('c:/')"
      ],
      "metadata": {
        "id": "yWe2S4joZtEW"
      },
      "id": "yWe2S4joZtEW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9123f58-25f7-48e3-810f-60206a8616b1",
      "metadata": {
        "id": "e9123f58-25f7-48e3-810f-60206a8616b1"
      },
      "outputs": [],
      "source": [
        "image_list_ds = tf.data.Dataset.list_files(image_list, shuffle=False)\n",
        "mask_list_ds = tf.data.Dataset.list_files(mask_list, shuffle=False)\n",
        "\n",
        "for path in zip(image_list_ds.take(3), mask_list_ds.take(3)):\n",
        "    print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72cad909-f737-472a-a415-ebf7ee21369b",
      "metadata": {
        "id": "72cad909-f737-472a-a415-ebf7ee21369b"
      },
      "outputs": [],
      "source": [
        "image_filenames = tf.constant(image_list)\n",
        "masks_filenames = tf.constant(mask_list)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((image_filenames, masks_filenames))\n",
        "\n",
        "for image, mask in dataset.take(1):\n",
        "    print(image)\n",
        "    print(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "126a8676-fae2-4c3c-bcaa-eb807c275cc7",
      "metadata": {
        "id": "126a8676-fae2-4c3c-bcaa-eb807c275cc7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "def normalize_image(img):\n",
        "    # Convert uint16 image to float32\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    # Min-Max Scaling: Normalize to [0, 1]\n",
        "    img_normalized = (img - tf.reduce_min(img)) / (tf.reduce_max(img) - tf.reduce_min(img))\n",
        "\n",
        "    return img_normalized\n",
        "\n",
        "def process_path(image_path, mask_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img_normalized = normalize_image(img)#img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=3)\n",
        "    mask = tf.math.reduce_max(mask, axis=-1, keepdims=True)\n",
        "    return img_normalized, mask\n",
        "\n",
        "def preprocess(image, mask):\n",
        "    input_image = tf.image.resize(image, (256, 256), method='nearest')\n",
        "    input_mask = tf.image.resize(mask, (256, 256), method='nearest')\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "image_ds = dataset.map(process_path)\n",
        "processed_image_ds = image_ds.map(preprocess)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = zip(*processed_image_ds)\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "id": "iqxH3RGtQFq0"
      },
      "id": "iqxH3RGtQFq0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e283b2fa-4050-4f74-aee7-72223c111a20",
      "metadata": {
        "id": "e283b2fa-4050-4f74-aee7-72223c111a20"
      },
      "outputs": [],
      "source": [
        "# UNQ_C1\n",
        "# GRADED FUNCTION: conv_block\n",
        "def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n",
        "    \"\"\"\n",
        "    Convolutional downsampling block\n",
        "\n",
        "    Arguments:\n",
        "        inputs -- Input tensor\n",
        "        n_filters -- Number of filters for the convolutional layers\n",
        "        dropout_prob -- Dropout probability\n",
        "        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n",
        "    Returns:\n",
        "        next_layer, skip_connection --  Next layer and skip connection outputs\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE\n",
        "    conv = Conv2D(n_filters, # Number of filters\n",
        "                  3,   # Kernel size\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal')(inputs)\n",
        "    conv = Conv2D(n_filters, # Number of filters\n",
        "                  3,   # Kernel size\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal')(conv)\n",
        "    ### END CODE HERE\n",
        "\n",
        "    # if dropout_prob > 0 add a dropout layer, with the variable dropout_prob as parameter\n",
        "    if dropout_prob > 0:\n",
        "         ### START CODE HERE\n",
        "        conv = Dropout(dropout_prob)(conv)\n",
        "         ### END CODE HERE\n",
        "\n",
        "\n",
        "    # if max_pooling is True add a MaxPooling2D with 2x2 pool_size\n",
        "    if max_pooling:\n",
        "        ### START CODE HERE\n",
        "        next_layer = MaxPooling2D(2,strides=2)(conv)\n",
        "        ### END CODE HERE\n",
        "\n",
        "    else:\n",
        "        next_layer = conv\n",
        "\n",
        "    skip_connection = conv\n",
        "\n",
        "    return next_layer, skip_connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e631e49-a542-4ce7-bc52-aa3845d80526",
      "metadata": {
        "id": "5e631e49-a542-4ce7-bc52-aa3845d80526"
      },
      "outputs": [],
      "source": [
        "# UNQ_C2\n",
        "# GRADED FUNCTION: upsampling_block\n",
        "def upsampling_block(expansive_input, contractive_input, n_filters=32):\n",
        "    \"\"\"\n",
        "    Convolutional upsampling block\n",
        "\n",
        "    Arguments:\n",
        "        expansive_input -- Input tensor from previous layer\n",
        "        contractive_input -- Input tensor from previous skip layer\n",
        "        n_filters -- Number of filters for the convolutional layers\n",
        "    Returns:\n",
        "        conv -- Tensor output\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE\n",
        "    up = Conv2DTranspose(\n",
        "                 n_filters,    # number of filters\n",
        "                 3,    # Kernel size\n",
        "                 strides=2,\n",
        "                 padding='same')(expansive_input)\n",
        "\n",
        "    # Merge the previous output and the contractive_input\n",
        "    merge = concatenate([up, contractive_input], axis=3)\n",
        "    conv = Conv2D(n_filters,   # Number of filters\n",
        "                 3,     # Kernel size\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer='he_normal')(merge)\n",
        "    conv = Conv2D(n_filters,   # Number of filters\n",
        "                 3,     # Kernel size\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer='he_normal')(conv)\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd060e0e-31ee-4ae5-9606-2da5656ce322",
      "metadata": {
        "id": "cd060e0e-31ee-4ae5-9606-2da5656ce322"
      },
      "outputs": [],
      "source": [
        "# UNQ_C3\n",
        "# GRADED FUNCTION: unet_model\n",
        "def unet_model(input_size=(256, 256, 3), n_filters=32, n_classes=1):\n",
        "    \"\"\"\n",
        "    Unet model\n",
        "\n",
        "    Arguments:\n",
        "        input_size -- Input shape\n",
        "        n_filters -- Number of filters for the convolutional layers\n",
        "        n_classes -- Number of output classes\n",
        "    Returns:\n",
        "        model -- tf.keras.Model\n",
        "    \"\"\"\n",
        "    inputs = Input(input_size)\n",
        "    # Contracting Path (encoding)\n",
        "    # Add a conv_block with the inputs of the unet_ model and n_filters\n",
        "    ### START CODE HERE\n",
        "    cblock1 = conv_block(inputs=inputs, n_filters=n_filters*1)\n",
        "    # Chain the first element of the output of each block to be the input of the next conv_block.\n",
        "    # Double the number of filters at each new step\n",
        "    cblock2 = conv_block(inputs=cblock1[0], n_filters=n_filters*2)\n",
        "    cblock3 = conv_block(inputs=cblock2[0], n_filters=n_filters*4)\n",
        "    cblock4 = conv_block(inputs=cblock3[0], n_filters=n_filters*8,dropout_prob=0.3) # Include a dropout_prob of 0.3 for this layer\n",
        "    # Include a dropout_prob of 0.3 for this layer, and avoid the max_pooling layer\n",
        "    cblock5 = conv_block(inputs=cblock4[0], n_filters=n_filters*16,dropout_prob=0.3, max_pooling=False)\n",
        "    ### END CODE HERE\n",
        "\n",
        "    # Expanding Path (decoding)\n",
        "    # Add the first upsampling_block.\n",
        "    # Use the cblock5[0] as expansive_input and cblock4[1] as contractive_input and n_filters * 8\n",
        "    ### START CODE HERE\n",
        "    ublock6 = upsampling_block(cblock5[0], cblock4[1], n_filters*8)\n",
        "    # Chain the output of the previous block as expansive_input and the corresponding contractive block output.\n",
        "    # Note that you must use the second element of the contractive block i.e before the maxpooling layer.\n",
        "    # At each step, use half the number of filters of the previous block\n",
        "    ublock7 = upsampling_block(ublock6, cblock3[1], n_filters*4)\n",
        "    ublock8 = upsampling_block(ublock7, cblock2[1], n_filters*2)\n",
        "    ublock9 = upsampling_block(ublock8, cblock1[1], n_filters*1)\n",
        "    ### END CODE HERE\n",
        "\n",
        "    conv9 = Conv2D(n_filters,\n",
        "                 3,\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer='he_normal')(ublock9)\n",
        "\n",
        "    # Add a Conv2D layer with n_classes filter, kernel size of 1 and a 'same' padding\n",
        "    ### START CODE HERE\n",
        "    conv10 = Conv2D(n_classes, 1, padding='same',activation='sigmoid')(conv9)\n",
        "    ### END CODE HERE\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edb64a69-b735-4f75-ae14-dba397985c24",
      "metadata": {
        "id": "edb64a69-b735-4f75-ae14-dba397985c24"
      },
      "outputs": [],
      "source": [
        "#import outputs\n",
        "from tensorflow.keras.utils import plot_model\n",
        "img_height =256\n",
        "img_width = 256\n",
        "num_channels = 3\n",
        "\n",
        "unet = unet_model((img_height, img_width, num_channels))\n",
        "#comparator(summary(unet), outputs.unet_model_output)\n",
        "#plot_model(unet, to_file='unet_mymodel.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe308449-8dc6-4b76-b4d4-1099ed43efa9",
      "metadata": {
        "id": "fe308449-8dc6-4b76-b4d4-1099ed43efa9"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from keras.optimizers import SGD\n",
        "opt = SGD(learning_rate=0.001)\n",
        "opt1= Adam(learning_rate=0.0001)\n",
        "#unet.summary()\n",
        "unet.compile(optimizer=opt1, loss=BinaryCrossentropy(), metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "057c8d60-e4da-44d6-aa57-b17caeebf40a",
      "metadata": {
        "id": "057c8d60-e4da-44d6-aa57-b17caeebf40a"
      },
      "outputs": [],
      "source": [
        "def display(display_list):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "UTl0hJh_vc5M"
      },
      "id": "UTl0hJh_vc5M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "bxDEUrBlgUeU"
      },
      "id": "bxDEUrBlgUeU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
        "model_history = unet.fit(X_train, y_train, batch_size=8, validation_data=(X_val, y_val),  callbacks=[early_stopping], epochs=20)"
      ],
      "metadata": {
        "id": "i8C_uWKZu2Ix"
      },
      "id": "i8C_uWKZu2Ix",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0TdOfoaO1Pk4"
      },
      "id": "0TdOfoaO1Pk4"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming model_history is the history object returned by model.fit()\n",
        "# Example: model_history = model.fit(...)\n",
        "\n",
        "# Extracting data\n",
        "epochs = range(1, len(model_history.history['accuracy']) + 1)\n",
        "accuracy = model_history.history['accuracy']\n",
        "val_accuracy = model_history.history.get('val_accuracy')\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history.get('val_loss')\n",
        "\n",
        "# Plotting Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "ax1 = plt.subplot(1, 2, 1)\n",
        "ax1.plot(epochs, accuracy, marker='o', linestyle='-', color='b', label='Training Accuracy')\n",
        "if val_accuracy:\n",
        "    ax1.plot(epochs, val_accuracy, marker='o', linestyle='--', color='g', label='Validation Accuracy')\n",
        "ax1.set_xlabel('Epoch', fontsize=14)\n",
        "ax1.set_ylabel('Accuracy', fontsize=14)\n",
        "ax1.set_title('Accuracy vs Epoch', fontsize=16)\n",
        "ax1.set_xticks(range(1, len(epochs) + 1, 2))  # Set x-axis interval to 2\n",
        "ax1.tick_params(axis='y', labelsize=12)  # Set y-ticks font size to 12\n",
        "ax1.legend(fontsize=14)\n",
        "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda val, pos: f'{val:.2f}'))\n",
        "\n",
        "# Plotting Loss\n",
        "ax2 = plt.subplot(1, 2, 2)\n",
        "ax2.plot(epochs, loss, marker='o', linestyle='-', color='r', label='Training Loss')\n",
        "if val_loss:\n",
        "    ax2.plot(epochs, val_loss, marker='o', linestyle='--', color='orange', label='Validation Loss')\n",
        "ax2.set_xlabel('Epoch', fontsize=14)\n",
        "ax2.set_ylabel('Loss', fontsize=14)\n",
        "ax2.set_title('Loss vs Epoch', fontsize=16)\n",
        "ax2.set_xticks(range(1, len(epochs) + 1, 2))  # Set x-axis interval to 2\n",
        "ax2.tick_params(axis='y', labelsize=12)  # Set y-ticks font size to 12\n",
        "ax2.legend(fontsize=14)\n",
        "ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda val, pos: f'{val:.2f}'))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YlJdzVwRUTcK"
      },
      "id": "YlJdzVwRUTcK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred =unet.predict(X_train)\n",
        "\n",
        "# Visualize a few examples\n",
        "for i in range(250):  # Adjust the range as needed\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(X_train[i])\n",
        "    plt.title(\"Original Image\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(y_pred[i], cmap='Greens')  # Predicted segmentation mask\n",
        "    plt.title(\"Predicted Segmentation\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(y_train[i], cmap='Greens')  # Ground truth segmentation mask\n",
        "    plt.title(\"Ground Truth\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NFqO8OJJ24sT"
      },
      "id": "NFqO8OJJ24sT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNet Segmentation Semantic"
      ],
      "metadata": {
        "id": "LYHJw973gYhK"
      },
      "id": "LYHJw973gYhK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from io import StringIO\n",
        "import sys\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "def unet_model(input_size=(128, 128, 3)):\n",
        "    inputs = Input(input_size)\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Decoder\n",
        "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
        "    merge6 = concatenate([conv4, up6], axis=3)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
        "    merge7 = concatenate([conv3, up7], axis=3)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = UpSampling2D(size=(2, 2))(conv7)\n",
        "    merge8 = concatenate([conv2, up8], axis=3)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = UpSampling2D(size=(2, 2))(conv8)\n",
        "    merge9 = concatenate([conv1, up9], axis=3)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs, conv10)\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "\n",
        "# Redirect stdout to capture print statements\n",
        "model = unet_model()\n",
        "model.summary()\n",
        "# Your code that prints to stdout\n",
        "\n",
        "plot_model(model, to_file='unet_model.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "2Jit2pDssnXM"
      },
      "id": "2Jit2pDssnXM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "model.compile(optimizer=SGD(learning_rate=0.0001), loss=BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VgZ5U4KjVyMb"
      },
      "id": "VgZ5U4KjVyMb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "eZCHO0JeQcLS"
      },
      "id": "eZCHO0JeQcLS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "mIYKzOvjwNOO"
      },
      "id": "mIYKzOvjwNOO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
        "model_history =model.fit(X_train, y_train, batch_size=8, validation_data=(X_val, y_val),  callbacks=[early_stopping], epochs=20)"
      ],
      "metadata": {
        "id": "_HM6vnS7Qoa6"
      },
      "id": "_HM6vnS7Qoa6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DeepLabV3+"
      ],
      "metadata": {
        "id": "bRkh5-qfgqJT"
      },
      "id": "bRkh5-qfgqJT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "base_model = tf.keras.applications.DenseNet121(input_shape=(128, 128, 3), include_top=False)\n",
        "base_model.trainable = True\n",
        "\n",
        "inputs = layers.Input(shape=(128, 128, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((32, 32))(x)\n",
        "outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "kwYndBp-Bwz9"
      },
      "id": "kwYndBp-Bwz9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "0aoQsrYtG7Wb"
      },
      "id": "0aoQsrYtG7Wb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "model.compile(optimizer=SGD(learning_rate=1e-4), loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_history = model.fit(X_train, y_train, batch_size=8, validation_data=(X_val, y_val), callbacks=[early_stopping], epochs=20)"
      ],
      "metadata": {
        "id": "zTVd2gCqDnrL"
      },
      "id": "zTVd2gCqDnrL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}