{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e06dd57f64a4cf28f02745e682cb0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb8fe32e71b5449389ccee4d1c72c778",
              "IPY_MODEL_a94b84466cae4c1c9a0a62a0f0de4637",
              "IPY_MODEL_312fc0411f454cdfb5c09d3dfe71368c"
            ],
            "layout": "IPY_MODEL_0770b506bec5452ab7b12c523c27c9e4"
          }
        },
        "cb8fe32e71b5449389ccee4d1c72c778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5304962efb6a4cad9b7f3cb42a7753b0",
            "placeholder": "​",
            "style": "IPY_MODEL_42a440095e19417e92e522ac146f7cbe",
            "value": "model.safetensors: 100%"
          }
        },
        "a94b84466cae4c1c9a0a62a0f0de4637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af09766c1af34c328bdb70f1f91c7a27",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1c3a4239a91420c966e2265cf4f01cf",
            "value": 346284714
          }
        },
        "312fc0411f454cdfb5c09d3dfe71368c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9214d3b939ad48d7bf89cf4a4969b429",
            "placeholder": "​",
            "style": "IPY_MODEL_7ed06f67f7854a579aa00a1a6328ce5f",
            "value": " 346M/346M [00:02&lt;00:00, 319MB/s]"
          }
        },
        "0770b506bec5452ab7b12c523c27c9e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5304962efb6a4cad9b7f3cb42a7753b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a440095e19417e92e522ac146f7cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af09766c1af34c328bdb70f1f91c7a27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c3a4239a91420c966e2265cf4f01cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9214d3b939ad48d7bf89cf4a4969b429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ed06f67f7854a579aa00a1a6328ce5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ma850419/Fast_UNet/blob/main/Copy_of_csiro_pasture_06jan2026_valbase16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EYv8NFfkrsQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b9a487-b60d-437b-ee73-08b076766b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcFi9Gve3tKb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Data Loading and Exploration\n",
        "from pathlib import Path\n",
        "class PastureDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir, transform=None, is_test=False):\n",
        "        \"\"\"\n",
        "        Dataset for pasture biomass prediction\n",
        "\n",
        "        Args:\n",
        "            csv_file: Path to csv file\n",
        "            image_dir: Directory with images\n",
        "            transform: Image transformations\n",
        "            is_test: Whether this is test data\n",
        "        \"\"\"\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "        # For training data, we need to handle multiple targets per image\n",
        "        if not is_test:\n",
        "            self.image_targets = self._prepare_training_data()\n",
        "\n",
        "    def _prepare_training_data(self):\n",
        "        \"\"\"Group targets by image for training\"\"\"\n",
        "        image_groups = self.data.groupby('image_path')\n",
        "        image_targets = {}\n",
        "\n",
        "        for image_path, group in image_groups:\n",
        "            targets = {}\n",
        "            for _, row in group.iterrows():\n",
        "                targets[row['target_name']] = row['target']\n",
        "            image_targets[image_path] = targets\n",
        "\n",
        "        return image_targets\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.is_test:\n",
        "            return len(self.data)\n",
        "        else:\n",
        "            return len(self.image_targets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_test:\n",
        "            sample = self.data.iloc[idx]\n",
        "            image_path = sample['image_path']  # already absolute\n",
        "            img = Image.open(image_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "\n",
        "            return {\n",
        "                'image': img,\n",
        "                'target_name': sample['target_name'],\n",
        "                'sample_id': sample['sample_id'],\n",
        "                'image_path': image_path\n",
        "            }\n",
        "        else:\n",
        "            image_path = list(self.image_targets.keys())[idx]\n",
        "            targets_dict = self.image_targets[image_path]\n",
        "\n",
        "            img = Image.open(image_path).convert('RGB')  # already absolute\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "\n",
        "            target_order = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
        "            targets = [targets_dict.get(name, 0.0) for name in target_order]\n",
        "            targets = torch.FloatTensor(targets)\n",
        "\n",
        "            return {\n",
        "                'image': img,\n",
        "                'targets': targets,\n",
        "                'image_path': image_path\n",
        "            }\n",
        "\n",
        "\n",
        "def explore_data():\n",
        "    \"\"\"Explore the training data distribution\"\"\"\n",
        "    train_df = pd.read_csv(\"/content/drive/MyDrive/csiro/csiro-biomass/train.csv\")\n",
        "\n",
        "    print(\"Training data shape:\", train_df.shape)\n",
        "    print(\"\\nTarget value distribution:\")\n",
        "    print(train_df.groupby('target_name')['target'].describe())\n",
        "\n",
        "    # Plot target distributions\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    targets = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
        "\n",
        "    for i, target in enumerate(targets):\n",
        "        target_data = train_df[train_df['target_name'] == target]['target']\n",
        "        axes[i].hist(target_data, bins=50, alpha=0.7)\n",
        "        axes[i].set_title(f'Distribution of {target}')\n",
        "        axes[i].set_xlabel('Biomass (g)')\n",
        "        axes[i].set_ylabel('Frequency')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Check for correlations between targets\n",
        "    pivot_df = train_df.pivot_table(index='sample_id', columns='target_name', values='target')\n",
        "    correlation_matrix = pivot_df.corr()\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "    plt.title('Correlation between Biomass Components')\n",
        "    plt.show()\n",
        "\n",
        "# Explore the data\n",
        "explore_data()"
      ],
      "metadata": {
        "id": "QOjmYkE23uGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PastureDataset(Dataset):\n",
        "    def __init__(self, df, transform=None, target_mean=None, target_std=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        self.target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
        "        self.target_mean = target_mean\n",
        "        self.target_std = target_std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        targets = row[self.target_cols].values.astype(np.float32)\n",
        "        if self.target_mean is not None:\n",
        "            targets = (targets - self.target_mean) / self.target_std\n",
        "\n",
        "        return {\n",
        "            \"image\": image,\n",
        "            \"targets\": torch.tensor(targets, dtype=torch.float32)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "pD0F2Di-t_uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vit-Base/16\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PastureBiomassModel(nn.Module):\n",
        "    def __init__(self, num_targets=5, pretrained=True):\n",
        "        super(PastureBiomassModel, self).__init__()\n",
        "\n",
        "        # -----------------------------\n",
        "        # ViT-Base/16 backbone (384x384)\n",
        "        # -----------------------------\n",
        "        self.backbone = timm.create_model(\n",
        "            \"vit_base_patch16_384\",\n",
        "            pretrained=pretrained,\n",
        "            num_classes=0   # remove classifier, output features only\n",
        "        )\n",
        "\n",
        "        in_features = self.backbone.num_features  # 768 for ViT-B/16\n",
        "\n",
        "        # Shared MLP head\n",
        "        self.shared_features = nn.Sequential(\n",
        "            nn.Linear(in_features, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "\n",
        "        # Multi-target regression heads\n",
        "        self.heads = nn.ModuleList([\n",
        "            nn.Linear(256, 1) for _ in range(num_targets)\n",
        "        ])\n",
        "\n",
        "        self.target_names = [\n",
        "            'Dry_Green_g',\n",
        "            'Dry_Dead_g',\n",
        "            'Dry_Clover_g',\n",
        "            'GDM_g',\n",
        "            'Dry_Total_g'\n",
        "        ]\n",
        "\n",
        "    def forward(self, x, target_name=None):\n",
        "        features = self.backbone(x)  # (B, 768)\n",
        "        shared_out = self.shared_features(features)\n",
        "\n",
        "        if target_name is not None:\n",
        "            # Inference for a specific target\n",
        "            target_idx = self.target_names.index(target_name)\n",
        "            output = self.heads[target_idx](shared_out)\n",
        "            return output\n",
        "        else:\n",
        "            # Training: predict all 5 targets\n",
        "            outputs = [head(shared_out) for head in self.heads]\n",
        "            return torch.cat(outputs, dim=1)\n"
      ],
      "metadata": {
        "id": "LTYr56-Kk5Wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTargetMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiTargetMSELoss, self).__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # predictions: (B, 5)\n",
        "        # targets: (B, 5)\n",
        "        loss = 0\n",
        "        for i in range(targets.shape[1]):\n",
        "            loss += self.mse(predictions[:, i], targets[:, i])\n",
        "        return loss / targets.shape[1]\n"
      ],
      "metadata": {
        "id": "wUQhXIx-pKtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset\n",
        "# -----------------------------\n",
        "class PastureDataset(Dataset):\n",
        "    def __init__(self, df, transform=None, target_mean=None, target_std=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        self.target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
        "        self.target_mean = target_mean\n",
        "        self.target_std = target_std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        targets = row[self.target_cols].values.astype(np.float32)\n",
        "        # Normalize targets for training stability (these are in log space if log1p is used upstream)\n",
        "        if self.target_mean is not None and self.target_std is not None:\n",
        "            targets = (targets - self.target_mean) / self.target_std\n",
        "\n",
        "        return {\"image\": image, \"targets\": torch.tensor(targets, dtype=torch.float32)}\n",
        "\n",
        "# -----------------------------\n",
        "# Model: ViT backbone + shared MLP head + 5 linear heads\n",
        "# -----------------------------\n",
        "class PastureBiomassModel(nn.Module):\n",
        "    def __init__(self, num_targets=5, backbone_name=\"vit_base_patch16_224\", pretrained=True, head_width=1024):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(backbone_name, pretrained=pretrained, num_classes=0)\n",
        "        in_features = self.backbone.num_features  # typically 768 for ViT-B\n",
        "\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Linear(in_features, head_width),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(head_width, head_width // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(head_width // 2, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.heads = nn.ModuleList([nn.Linear(256, 1) for _ in range(num_targets)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)           # (B, 768)\n",
        "        h = self.shared(feats)             # (B, 256)\n",
        "        outs = [head(h) for head in self.heads]\n",
        "        return torch.cat(outs, dim=1)      # (B, num_targets)\n",
        "\n",
        "# -----------------------------\n",
        "# Training\n",
        "# -----------------------------\n",
        "def train_model(csv_path=\"/content/drive/MyDrive/csiro/csiro-biomass/train.csv\",\n",
        "                backbone_name=\"vit_base_patch16_224\",\n",
        "                input_size=224,\n",
        "                batch_size=16,\n",
        "                lr=1e-4,\n",
        "                weight_decay=1e-4,\n",
        "                warmup_freeze_epochs=10,\n",
        "                num_epochs=60,\n",
        "                use_loss_weights=True,\n",
        "                apply_log1p=True):\n",
        "\n",
        "    # 1) Transforms (match backbone resolution)\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    # 2) Load and pivot\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df_wide = df.pivot_table(\n",
        "        index=[\"sample_id\", \"image_path\"],\n",
        "        columns=\"target_name\",\n",
        "        values=\"target\"\n",
        "    ).reset_index()\n",
        "    df_wide.columns.name = None\n",
        "\n",
        "    target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
        "\n",
        "    # Clean: drop rows if all targets missing, fill partial missing with 0\n",
        "    df_wide = df_wide.dropna(how=\"all\", subset=target_cols)\n",
        "    df_wide[target_cols] = df_wide[target_cols].fillna(0)\n",
        "\n",
        "    if len(df_wide) == 0:\n",
        "        raise ValueError(\"No samples left after cleaning.\")\n",
        "\n",
        "    # 3) Split BEFORE stats\n",
        "    train_size = int(0.7 * len(df_wide))\n",
        "    train_df = df_wide.sample(n=train_size, random_state=42)\n",
        "    val_df = df_wide.drop(train_df.index)\n",
        "\n",
        "    # Log scaling to stabilize skew (optional, default True)\n",
        "    if apply_log1p:\n",
        "        train_df[target_cols] = np.log1p(train_df[target_cols])\n",
        "        val_df[target_cols] = np.log1p(val_df[target_cols])\n",
        "\n",
        "    # Compute mean/std on training set only (in whatever space targets currently are)\n",
        "    target_mean = train_df[target_cols].mean().values.astype(np.float32)\n",
        "    target_std = train_df[target_cols].std(ddof=0).values.astype(np.float32)\n",
        "    target_std = np.where(target_std < 1e-6, 1e-6, target_std)\n",
        "\n",
        "    print(\"Target mean:\", target_mean)\n",
        "    print(\"Target std:\", target_std)\n",
        "\n",
        "    # 4) Datasets & loaders\n",
        "    train_dataset = PastureDataset(train_df, transform=train_transform,\n",
        "                                   target_mean=target_mean, target_std=target_std)\n",
        "    val_dataset = PastureDataset(val_df, transform=val_transform,\n",
        "                                 target_mean=target_mean, target_std=target_std)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # 5) Model, loss, optimizer, scheduler\n",
        "    model = PastureBiomassModel(backbone_name=backbone_name, num_targets=5).to(device)\n",
        "\n",
        "    # Freeze backbone for warmup epochs\n",
        "    def set_backbone_requires_grad(flag):\n",
        "        for p in model.backbone.parameters():\n",
        "            p.requires_grad = flag\n",
        "\n",
        "    set_backbone_requires_grad(False)\n",
        "\n",
        "    base_criterion = nn.MSELoss(reduction='none')\n",
        "    loss_weights = torch.tensor(1.0 / target_std, dtype=torch.float32, device=device) if use_loss_weights else None\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'epoch # {epoch}')\n",
        "        if epoch == warmup_freeze_epochs:\n",
        "            set_backbone_requires_grad(True)\n",
        "\n",
        "        # ---------------- Train ----------------\n",
        "        model.train()\n",
        "        running_train_loss = 0.0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            images = batch['image'].to(device, non_blocking=True)\n",
        "            targets = batch['targets'].to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            outputs = model(images)\n",
        "\n",
        "            loss_per_target = base_criterion(outputs, targets)  # (B, 5)\n",
        "            if loss_weights is not None:\n",
        "                loss_per_target = loss_per_target * loss_weights  # weighted MSE per target\n",
        "\n",
        "            loss = loss_per_target.mean()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            running_train_loss += loss.item()\n",
        "\n",
        "        train_loss = running_train_loss / max(1, len(train_loader))\n",
        "        train_losses.append(train_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.6f}\")\n",
        "\n",
        "        # ---------------- Validate ----------------\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        all_preds, all_targets = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                images = batch['image'].to(device, non_blocking=True)\n",
        "                targets = batch['targets'].to(device, non_blocking=True)\n",
        "\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Validation loss on normalized values\n",
        "                val_loss_per_target = base_criterion(outputs, targets)\n",
        "                if loss_weights is not None:\n",
        "                    val_loss_per_target = val_loss_per_target * loss_weights\n",
        "                batch_val_loss = val_loss_per_target.mean().item()\n",
        "                running_val_loss += batch_val_loss\n",
        "\n",
        "                # Denormalize back to original target space (log space if apply_log1p=True)\n",
        "                preds = outputs.cpu().numpy()\n",
        "                targets_np = targets.cpu().numpy()\n",
        "                preds = preds * target_std + target_mean\n",
        "                targets_np = targets_np * target_std + target_mean\n",
        "\n",
        "                # If log1p was applied, invert to grams for metrics\n",
        "                if apply_log1p:\n",
        "                    preds = np.expm1(preds)\n",
        "                    targets_np = np.expm1(targets_np)\n",
        "\n",
        "                all_preds.append(preds)\n",
        "                all_targets.append(targets_np)\n",
        "\n",
        "        val_loss = running_val_loss / max(1, len(val_loader))\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        all_preds = np.vstack(all_preds)\n",
        "        all_targets = np.vstack(all_targets)\n",
        "\n",
        "        # Per-target R² (in grams if apply_log1p=True)\n",
        "        for i, name in enumerate(target_cols):\n",
        "            r2_i = r2_score(all_targets[:, i], all_preds[:, i])\n",
        "            print(f\"{name}: R² = {r2_i:.4f}\")\n",
        "\n",
        "        # Overall R²\n",
        "        r2_overall = r2_score(all_targets, all_preds, multioutput='uniform_average')\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]: Val Loss: {val_loss:.6f}, Overall R²: {r2_overall:.4f}\")\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Save best by val loss\n",
        "        if val_loss < best_val_loss and not np.isnan(val_loss):\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_pasture_model.pth')\n",
        "            print(\"Saved best_pasture_model.pth\")\n",
        "\n",
        "    # ---------------- Plot ----------------\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training History')\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Run\n",
        "if __name__ == \"__main__\":\n",
        "    model = train_model(\n",
        "        csv_path=\"/content/drive/MyDrive/csiro/csiro-biomass/train.csv\",\n",
        "        backbone_name=\"vit_base_patch16_224\",  # set to \"vit_base_patch16_384\" with input_size=384 if desired\n",
        "        input_size=224,\n",
        "        batch_size=16,\n",
        "        lr=1e-4,\n",
        "        weight_decay=1e-4,\n",
        "        warmup_freeze_epochs=10,\n",
        "        num_epochs=60,\n",
        "        use_loss_weights=True,\n",
        "        apply_log1p=True  # controls log scaling usage\n",
        "    )\n",
        "    torch.save(model.state_dict(), \"/content/drive/MyDrive/csiro/vitbase_60epochs.pth\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d1zvy5v1k_nn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "0e06dd57f64a4cf28f02745e682cb0f2",
            "cb8fe32e71b5449389ccee4d1c72c778",
            "a94b84466cae4c1c9a0a62a0f0de4637",
            "312fc0411f454cdfb5c09d3dfe71368c",
            "0770b506bec5452ab7b12c523c27c9e4",
            "5304962efb6a4cad9b7f3cb42a7753b0",
            "42a440095e19417e92e522ac146f7cbe",
            "af09766c1af34c328bdb70f1f91c7a27",
            "c1c3a4239a91420c966e2265cf4f01cf",
            "9214d3b939ad48d7bf89cf4a4969b429",
            "7ed06f67f7854a579aa00a1a6328ce5f"
          ]
        },
        "outputId": "3eceb54f-0adb-4b4d-d38f-5e0c20fef487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target mean: [0.5662349  0.39181235 0.23558907 0.6603299  0.7512836 ]\n",
            "Target std: [1.2482067  0.92493486 0.73027366 1.3471655  1.4974451 ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e06dd57f64a4cf28f02745e682cb0f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch # 0\n",
            "Epoch [1/60], Train Loss: 0.927332\n",
            "Dry_Green_g: R² = -0.0752\n",
            "Dry_Dead_g: R² = -0.0822\n",
            "Dry_Clover_g: R² = -0.0248\n",
            "GDM_g: R² = -0.1044\n",
            "Dry_Total_g: R² = -0.1184\n",
            "Epoch [1/60]: Val Loss: 0.967470, Overall R²: -0.0810\n",
            "Saved best_pasture_model.pth\n",
            "epoch # 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation\n",
        "model.eval()\n",
        "val_loss = 0.0\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        images = batch['image'].to(device, non_blocking=True)\n",
        "        targets = batch['targets'].to(device, non_blocking=True)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        if torch.isnan(loss):\n",
        "            print(\"NaN detected in validation loss, skipping batch\")\n",
        "            continue\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        # -----------------------------\n",
        "        # Denormalize predictions + targets for metrics\n",
        "        # -----------------------------\n",
        "        preds = outputs.cpu().numpy()\n",
        "        targets_np = targets.cpu().numpy()\n",
        "\n",
        "        preds = preds * target_std + target_mean\n",
        "        targets_np = targets_np * target_std + target_mean\n",
        "\n",
        "        all_preds.append(preds)\n",
        "        all_targets.append(targets_np)\n",
        "\n",
        "val_loss /= max(1, len(val_loader))\n",
        "train_losses.append(train_loss)\n",
        "val_losses.append(val_loss)\n",
        "\n",
        "scheduler.step(val_loss)\n",
        "\n",
        "print(f\"Epoch [{epoch+1}/{num_epochs}]: Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "# After loop: compute R² in original units\n",
        "all_preds = np.vstack(all_preds)\n",
        "all_targets = np.vstack(all_targets)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "r2 = r2_score(all_targets, all_preds)\n",
        "print(f\"Validation R²: {r2:.4f}\")\n"
      ],
      "metadata": {
        "id": "DpeJotYvbML0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Multi-Target Regression Model\n",
        "class PastureBiomassModel(nn.Module):\n",
        "    def __init__(self, num_targets=5, pretrained=True):\n",
        "        super(PastureBiomassModel, self).__init__()\n",
        "\n",
        "        # Use EfficientNet as backbone\n",
        "        '''self.backbone = models.efficientnet_b0(pretrained=pretrained)\n",
        "\n",
        "        # Replace classifier\n",
        "        in_features = self.backbone.classifier[1].in_features\n",
        "        self.backbone.classifier = nn.Identity()  # Remove original classifier'''\n",
        "        self.backbone = models.resnet50(pretrained=pretrained)\n",
        "        # Replace final fully connected layer\n",
        "        in_features = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Identity()  # Remove original head\n",
        "\n",
        "        # Multi-target regression heads\n",
        "        self.shared_features = nn.Sequential(\n",
        "            nn.Linear(in_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        # Individual heads for each target\n",
        "        self.heads = nn.ModuleList([\n",
        "            nn.Linear(256, 1) for _ in range(num_targets)\n",
        "        ])\n",
        "\n",
        "        self.target_names = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
        "\n",
        "    def forward(self, x, target_name=None):\n",
        "        features = self.backbone(x)\n",
        "        shared_out = self.shared_features(features)\n",
        "\n",
        "        if target_name is not None:\n",
        "            # For test time - specific target\n",
        "            target_idx = self.target_names.index(target_name)\n",
        "            output = self.heads[target_idx](shared_out)\n",
        "            return output\n",
        "        else:\n",
        "            # For training - all targets\n",
        "            outputs = [head(shared_out) for head in self.heads]\n",
        "            return torch.cat(outputs, dim=1)\n",
        "\n",
        "class MultiTargetMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiTargetMSELoss, self).__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # Calculate MSE for each target and average\n",
        "        loss = 0\n",
        "        for i in range(targets.shape[1]):\n",
        "            loss += self.mse(predictions[:, i], targets[:, i])\n",
        "        return loss / targets.shape[1]"
      ],
      "metadata": {
        "id": "UdaxhoBA30Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Ensure your PastureBiomassModel (ViT-Base/16 backbone) is defined/imported\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset (expects a wide DataFrame)\n",
        "# -----------------------------\n",
        "class PastureDataset(Dataset):\n",
        "    def __init__(self, df, transform=None, target_mean=None, target_std=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        self.target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
        "        self.target_mean = target_mean\n",
        "        self.target_std = target_std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        targets = row[self.target_cols].values.astype(np.float32)\n",
        "        # standardize targets\n",
        "        if self.target_mean is not None and self.target_std is not None:\n",
        "            targets = (targets - self.target_mean) / self.target_std\n",
        "\n",
        "        return {\n",
        "            \"image\": image,\n",
        "            \"targets\": torch.tensor(targets, dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "\n",
        "def train_model():\n",
        "    # -----------------------------\n",
        "    # 1. Data transformations (ViT normalization)\n",
        "    # -----------------------------\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((384, 384)),\n",
        "        transforms.RandomResizedCrop(384, scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(0.3),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((384, 384)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    # -----------------------------\n",
        "    # 2. Load CSV, pivot to wide format, clean, compute stats\n",
        "    # -----------------------------\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/csiro/csiro-biomass/train.csv\")\n",
        "\n",
        "    df_wide = df.pivot_table(\n",
        "        index=[\"sample_id\", \"image_path\"],\n",
        "        columns=\"target_name\",\n",
        "        values=\"target\"\n",
        "    ).reset_index()\n",
        "    df_wide.columns.name = None\n",
        "\n",
        "    target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
        "    df_wide[target_cols] = df_wide[target_cols].fillna(0)\n",
        "\n",
        "    target_mean = df_wide[target_cols].mean().values.astype(np.float32)\n",
        "    target_std = df_wide[target_cols].std(ddof=0).values.astype(np.float32)\n",
        "    target_std = np.where(target_std < 1e-6, 1e-6, target_std)\n",
        "\n",
        "    print(\"Target mean:\", target_mean)\n",
        "    print(\"Target std:\", target_std)\n",
        "\n",
        "    # -----------------------------\n",
        "    # 3. Dataset and loaders\n",
        "    # -----------------------------\n",
        "    full_dataset = PastureDataset(\n",
        "        df_wide,\n",
        "        transform=train_transform,\n",
        "        target_mean=target_mean,\n",
        "        target_std=target_std\n",
        "    )\n",
        "\n",
        "    train_size = int(0.60 * len(full_dataset))\n",
        "    val_size = len(full_dataset) - train_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "    # apply val transform\n",
        "    val_dataset.dataset.transform = val_transform\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # -----------------------------\n",
        "    # 4. Model, loss, optimizer, scheduler\n",
        "    # -----------------------------\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = PastureBiomassModel(num_targets=5).to(device)\n",
        "\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
        "\n",
        "    # -----------------------------\n",
        "    # 5. Training loop with gradient clipping and unified validation+R²\n",
        "    # -----------------------------\n",
        "    best_val_loss = float('inf')\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    num_epochs = 25\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('epoch #', epoch)\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for step, batch in enumerate(train_loader, 1):\n",
        "            images = batch['image'].to(device, non_blocking=True)\n",
        "            targets = batch['targets'].to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"NaN loss at step {step}, skipping batch\")\n",
        "                continue\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= max(1, len(train_loader))\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # -------- Validation (loss + R² in one pass) --------\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                images = batch['image'].to(device, non_blocking=True)\n",
        "                targets = batch['targets'].to(device, non_blocking=True)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, targets)\n",
        "                if torch.isnan(loss):\n",
        "                    print(\"NaN detected in validation loss, skipping batch\")\n",
        "                    continue\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                all_preds.append(outputs.cpu().numpy())\n",
        "                all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "        val_loss /= max(1, len(val_loader))\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        # Compute R² (de-standardized)\n",
        "        all_preds = np.concatenate(all_preds, axis=0)\n",
        "        all_targets = np.concatenate(all_targets, axis=0)\n",
        "        all_preds = all_preds * target_std + target_mean\n",
        "        all_targets = all_targets * target_std + target_mean\n",
        "\n",
        "        r2_scores = []\n",
        "        for i, col in enumerate(target_cols):\n",
        "            r2_scores.append(r2_score(all_targets[:, i], all_preds[:, i]))\n",
        "        mean_r2 = float(np.mean(r2_scores))\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]: Val Loss: {val_loss:.4f}, Mean R²: {mean_r2:.4f}\")\n",
        "        print(\"Per-target R²:\", {col: round(r, 3) for col, r in zip(target_cols, r2_scores)})\n",
        "\n",
        "        # Step scheduler and save best\n",
        "        scheduler.step(val_loss)\n",
        "        if val_loss < best_val_loss and not np.isnan(val_loss):\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_pasture_model.pth')\n",
        "            print(\"Saved best_pasture_model.pth\")\n",
        "\n",
        "    # -----------------------------\n",
        "    # 6. Plot training history\n",
        "    # -----------------------------\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training History')\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Run training\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    model = train_model()\n",
        "    torch.save(model.state_dict(), f\"/content/drive/MyDrive/csiro/vitbase_25epochs.pth\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eXXJhlee36Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Prediction and Submission\n",
        "def create_submission():\n",
        "    \"\"\"Create submission file for test data\"\"\"\n",
        "\n",
        "    # Load test data\n",
        "    test_df = pd.read_csv('/content/drive/MyDrive/csiro/csiro-biomass/test.csv')\n",
        "    submission_df = pd.read_csv('/content/drive/MyDrive/csiro/csiro-biomass/sample_submission.csv')\n",
        "\n",
        "    # Load trained model\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = PastureBiomassModel(num_targets=5)\n",
        "    model.load_state_dict(torch.load('best_pasture_model.pth', map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Test transformations\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize((384, 384)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    full_dataset = PastureDataset(\n",
        "        \"/content/drive/MyDrive/csiro/csiro-biomass/test.csv\",\n",
        "        image_dir=None)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "    predictions = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            images = batch['image'].to(device)\n",
        "            target_names = batch['target_name']\n",
        "            sample_ids = batch['sample_id']\n",
        "\n",
        "            for i, (sample_id, target_name) in enumerate(zip(sample_ids, target_names)):\n",
        "                # Get prediction for specific target\n",
        "                output = model(images[i].unsqueeze(0), target_name)\n",
        "                prediction = output.item()\n",
        "\n",
        "                # Ensure non-negative predictions\n",
        "                prediction = max(0, prediction)\n",
        "                predictions[sample_id] = prediction\n",
        "\n",
        "    # Create submission\n",
        "    submission_df['target'] = submission_df['sample_id'].map(predictions)\n",
        "\n",
        "    # Fill any missing values with median from training data\n",
        "    train_df = pd.read_csv('/content/drive/MyDrive/csiro/csiro-biomass/train.csv')\n",
        "    target_medians = train_df.groupby('target_name')['target'].median()\n",
        "\n",
        "    for sample_id in submission_df[submission_df['target'].isna()]['sample_id']:\n",
        "        target_name = test_df[test_df['sample_id'] == sample_id]['target_name'].iloc[0]\n",
        "        submission_df.loc[submission_df['sample_id'] == sample_id, 'target'] = target_medians[target_name]\n",
        "\n",
        "    # Save submission\n",
        "    submission_df.to_csv('/content/drive/MyDrive/csiro/submission.csv', index=False)\n",
        "    print(\"Submission file created: submission.csv\")\n",
        "\n",
        "    # Show prediction statistics\n",
        "    print(\"\\nPrediction Statistics:\")\n",
        "    print(submission_df['target'].describe())\n",
        "\n",
        "    return submission_df\n",
        "\n",
        "# Create submission\n",
        "\n",
        "submission = create_submission()"
      ],
      "metadata": {
        "id": "I4233PLT3_6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replacement of the above PastureData\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class PastureDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir, transform=None, is_test=False, apply_log=True):\n",
        "        \"\"\"\n",
        "        Dataset for pasture biomass prediction.\n",
        "\n",
        "        Args:\n",
        "            csv_file: Path to csv file\n",
        "            image_dir: Directory with images\n",
        "            transform: Image transformations\n",
        "            is_test: Whether this is test data\n",
        "            apply_log: Apply log1p transform to targets (recommended)\n",
        "        \"\"\"\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "        self.apply_log = apply_log\n",
        "\n",
        "        # For training data, group all targets belonging to the same image\n",
        "        if not is_test:\n",
        "            self.image_targets = self._prepare_training_data()\n",
        "\n",
        "        # Fixed target order required by the model\n",
        "        self.target_order = [\n",
        "            'Dry_Green_g',\n",
        "            'Dry_Dead_g',\n",
        "            'Dry_Clover_g',\n",
        "            'GDM_g',\n",
        "            'Dry_Total_g'\n",
        "        ]\n",
        "\n",
        "    def _prepare_training_data(self):\n",
        "        \"\"\"Group targets by image for training\"\"\"\n",
        "        image_groups = self.data.groupby('image_path')\n",
        "        image_targets = {}\n",
        "\n",
        "        for image_path, group in image_groups:\n",
        "            targets = {}\n",
        "            for _, row in group.iterrows():\n",
        "                targets[row['target_name']] = row['target']\n",
        "            image_targets[image_path] = targets\n",
        "\n",
        "        return image_targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) if self.is_test else len(self.image_targets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_test:\n",
        "            # Test mode: return image + metadata only\n",
        "            sample = self.data.iloc[idx]\n",
        "            image_path = sample['image_path']\n",
        "            img = Image.open(image_path).convert('RGB')\n",
        "\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "\n",
        "            return {\n",
        "                'image': img,\n",
        "                'target_name': sample['target_name'],\n",
        "                'sample_id': sample['sample_id'],\n",
        "                'image_path': image_path\n",
        "            }\n",
        "\n",
        "        # Training mode\n",
        "        image_path = list(self.image_targets.keys())[idx]\n",
        "        targets_dict = self.image_targets[image_path]\n",
        "\n",
        "        # Load image\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # Extract targets in correct order\n",
        "        targets = np.array([targets_dict.get(name, 0.0) for name in self.target_order], dtype=float)\n",
        "\n",
        "        # ✅ Apply log1p transform (recommended for regression stability)\n",
        "        if self.apply_log:\n",
        "            targets = np.log1p(targets)\n",
        "\n",
        "        targets = torch.FloatTensor(targets)\n",
        "\n",
        "        return {\n",
        "            'image': img,\n",
        "            'targets': targets,\n",
        "            'image_path': image_path\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "bNDXgTVxQ3fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_submission():\n",
        "    \"\"\"Create submission file for test data\"\"\"\n",
        "\n",
        "    # Load test data\n",
        "    test_df = pd.read_csv('/content/drive/MyDrive/csiro/csiro-biomass/test.csv')\n",
        "    submission_df = pd.read_csv('/content/drive/MyDrive/csiro/csiro-biomass/sample_submission.csv')\n",
        "\n",
        "    # Load trained model\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = PastureBiomassModel(num_targets=5)\n",
        "    model.load_state_dict(torch.load('best_pasture_model.pth', map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Test transformations\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize((384, 384)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # ✅ Correct dataset instantiation\n",
        "    test_dataset = PastureDataset(\n",
        "        \"/content/drive/MyDrive/csiro/csiro-biomass/test.csv\",\n",
        "        image_dir=None,\n",
        "        transform=test_transform,\n",
        "        is_test=True\n",
        "    )\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "    predictions = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            images = batch['image'].to(device)\n",
        "            target_names = batch['target_name']\n",
        "            sample_ids = batch['sample_id']\n",
        "\n",
        "            for i, (sample_id, target_name) in enumerate(zip(sample_ids, target_names)):\n",
        "                output = model(images[i].unsqueeze(0), target_name)\n",
        "                prediction = max(0, output.item())  # ensure non-negative\n",
        "                predictions[sample_id] = prediction\n",
        "\n",
        "    # Create submission\n",
        "    submission_df['target'] = submission_df['sample_id'].map(predictions)\n",
        "\n",
        "    # Fill missing values with medians\n",
        "    train_df = pd.read_csv('/content/drive/MyDrive/csiro/csiro-biomass/train.csv')\n",
        "    target_medians = train_df.groupby('target_name')['target'].median()\n",
        "\n",
        "    for sample_id in submission_df[submission_df['target'].isna()]['sample_id']:\n",
        "        target_name = test_df[test_df['sample_id'] == sample_id]['target_name'].iloc[0]\n",
        "        submission_df.loc[submission_df['sample_id'] == sample_id, 'target'] = target_medians[target_name]\n",
        "\n",
        "    # Save submission\n",
        "    submission_df.to_csv('/content/drive/MyDrive/csiro/submission.csv', index=False)\n",
        "    print(\"Submission file created: submission.csv\")\n",
        "\n",
        "    print(\"\\nPrediction Statistics:\")\n",
        "    print(submission_df['target'].describe())\n",
        "\n",
        "    return submission_df\n",
        "\n",
        "submission = create_submission()\n"
      ],
      "metadata": {
        "id": "VPzEtLfqjwHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTargetWrapper(nn.Module):\n",
        "    def __init__(self, backbone, in_features, num_targets=5):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.shared_features = nn.Sequential(\n",
        "            nn.Linear(in_features, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "        # Each head predicts a continuous biomass weight\n",
        "        self.heads = nn.ModuleList([nn.Linear(512, 1) for _ in range(num_targets)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        if x.dim() > 2:\n",
        "            x = torch.flatten(x, 1)\n",
        "        shared = self.shared_features(x)\n",
        "        outputs = [head(shared) for head in self.heads]\n",
        "        return torch.cat(outputs, dim=1)  # shape: (batch, num_targets)\n"
      ],
      "metadata": {
        "id": "tbMzI_htH-3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "model_paths = {\n",
        "    'mobilenet_v2': \"/content/drive/MyDrive/csiro/mobilenet_v2.pth\",\n",
        "    'googlenet': \"/content/drive/MyDrive/csiro/googlenet.pth\",\n",
        "    'alexnet': \"/content/drive/MyDrive/csiro/alexnet.pth\",\n",
        "    'resnet50': \"/content/drive/MyDrive/csiro/resnet50.pth\",\n",
        "    'convnext_tiny': \"/content/drive/MyDrive/csiro/convnext_tiny.pth\",\n",
        "    'efficientnet_b0': \"/content/drive/MyDrive/csiro/efficientnet_b0.pth\"\n",
        "}\n",
        "\n",
        "\n",
        "def build_model(arch, num_targets=5, load_weights=False, device='cpu'):\n",
        "    if arch == 'mobilenet_v2':\n",
        "\n",
        "        backbone = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        # ✅ Extract correct feature size (1280)\n",
        "        in_features = backbone.classifier[1].in_features\n",
        "\n",
        "        # ✅ Remove classifier\n",
        "        backbone.classifier = nn.Identity()\n",
        "    elif arch == 'googlenet':\n",
        "        backbone = models.googlenet(weights=None, aux_logits=False)\n",
        "        in_features = backbone.fc.in_features\n",
        "        backbone.fc = nn.Identity()\n",
        "    elif arch == 'alexnet':\n",
        "        backbone = models.alexnet(weights=None)\n",
        "        # Flatten the conv output (256*6*6 = 9216)\n",
        "        in_features = 9216\n",
        "        backbone.classifier = nn.Sequential(\n",
        "            nn.Flatten()\n",
        "        )\n",
        "    elif arch == 'resnet50':\n",
        "        backbone = models.resnet50(weights=None)\n",
        "        in_features = backbone.fc.in_features\n",
        "        backbone.fc = nn.Identity()\n",
        "    elif arch == \"convnext_tiny\":\n",
        "        backbone = models.convnext_tiny(weights=None)\n",
        "        in_features = backbone.classifier[2].in_features\n",
        "        backbone.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "    elif arch == 'efficientnet_b0':\n",
        "        backbone = models.efficientnet_b0(weights=None)\n",
        "        in_features = backbone.classifier[1].in_features\n",
        "        backbone.classifier = nn.Identity()\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported architecture: {arch}\")\n",
        "\n",
        "    model = MultiTargetWrapper(backbone, in_features, num_targets=5)\n",
        "\n",
        "    if load_weights:\n",
        "        path = model_paths.get(arch)\n",
        "        if path:\n",
        "            state = torch.load(path, map_location=device)\n",
        "            model.load_state_dict(state, strict=True)\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"No path found for architecture: {arch}\")\n",
        "\n",
        "    return model'''\n"
      ],
      "metadata": {
        "id": "_Hv76CvKR6g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/ultralytics.git\n"
      ],
      "metadata": {
        "id": "JIAtpLi6zbpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n"
      ],
      "metadata": {
        "id": "jWiHRPJ-w3AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_LSTM_BiomassEstimator(nn.Module):\n",
        "    def __init__(self, backbone, feature_dim, hidden_dim=256, num_layers=1, num_targets=1):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "\n",
        "        # LSTM for temporal modeling\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=feature_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Regression head for biomass\n",
        "        self.fc = nn.Linear(hidden_dim, num_targets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Accepts:\n",
        "            (B, C, H, W)  -> single image\n",
        "            (B, T, C, H, W) -> sequence of images\n",
        "        \"\"\"\n",
        "\n",
        "        # 🔥 Automatically convert single images into a sequence of length 1\n",
        "        if x.dim() == 4:\n",
        "            x = x.unsqueeze(1)   # (B, 1, C, H, W)\n",
        "\n",
        "        # Now safe to unpack\n",
        "        b, t, c, h, w = x.shape\n",
        "\n",
        "        # Merge batch + time for CNN\n",
        "        x = x.view(b * t, c, h, w)\n",
        "\n",
        "        # Extract CNN features\n",
        "        feats = self.backbone(x)  # (b*t, feature_dim)\n",
        "\n",
        "        # Restore sequence structure\n",
        "        feats = feats.view(b, t, -1)\n",
        "\n",
        "        # LSTM\n",
        "        lstm_out, _ = self.lstm(feats)\n",
        "\n",
        "        # Predict using last timestep\n",
        "        out = self.fc(lstm_out[:, -1, :])\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "mFjGZa1yYudN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "# from ultralytics import YOLO   # uncomment if using YOLO\n",
        "\n",
        "model_paths = {\n",
        "    'mobilenet_v2': \"/content/drive/MyDrive/csiro/mobilenet_v2.pth\",\n",
        "    'googlenet': \"/content/drive/MyDrive/csiro/googlenet.pth\",\n",
        "    'alexnet': \"/content/drive/MyDrive/csiro/alexnet.pth\",\n",
        "    'resnet50': \"/content/drive/MyDrive/csiro/resnet50.pth\",\n",
        "    'convnext_tiny': \"/content/drive/MyDrive/csiro/convnext_tiny.pth\",\n",
        "    'efficientnet_b0': \"/content/drive/MyDrive/csiro/efficientnet_b0.pth\",\n",
        "    'yolov11': \"/content/drive/MyDrive/csiro/yolov11.pt\",\n",
        "    'yolov12': \"/content/drive/MyDrive/csiro/yolov12.pt\"\n",
        "}\n",
        "\n",
        "def build_model(\n",
        "    arch,\n",
        "    num_targets=5,\n",
        "    use_lstm=False,\n",
        "    hidden_dim=256,\n",
        "    num_layers=1,\n",
        "    load_weights=False,\n",
        "    device='cpu'\n",
        "):\n",
        "    # -----------------------------\n",
        "    # CNN BACKBONES\n",
        "    # -----------------------------\n",
        "    if arch == 'mobilenet_v2':\n",
        "        backbone = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
        "        in_features = backbone.classifier[1].in_features\n",
        "        backbone.classifier = nn.Identity()\n",
        "        if use_lstm:\n",
        "            return CNN_LSTM_BiomassEstimator(\n",
        "                backbone=backbone,              # ✅ use backbone directly\n",
        "                feature_dim=in_features,        # ✅ use in_features\n",
        "                hidden_dim=hidden_dim,\n",
        "                num_layers=num_layers,\n",
        "                num_targets=num_targets\n",
        "            )\n",
        "\n",
        "    elif arch == 'googlenet':\n",
        "        backbone = models.googlenet(weights=None, aux_logits=False)\n",
        "        in_features = backbone.fc.in_features\n",
        "        backbone.fc = nn.Identity()\n",
        "\n",
        "    elif arch == 'alexnet':\n",
        "        backbone = models.alexnet(weights=None)\n",
        "        in_features = 9216\n",
        "        backbone.classifier = nn.Sequential(nn.Flatten())\n",
        "\n",
        "    elif arch == 'resnet50':\n",
        "        backbone = models.resnet50(weights=None)\n",
        "        in_features = backbone.fc.in_features\n",
        "        backbone.fc = nn.Identity()\n",
        "\n",
        "    elif arch == \"convnext_tiny\":\n",
        "        backbone = models.convnext_tiny(weights=None)\n",
        "        in_features = backbone.classifier[2].in_features\n",
        "        backbone.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "    elif arch == 'efficientnet_b0':\n",
        "        backbone = models.efficientnet_b0(weights=None)\n",
        "        in_features = backbone.classifier[1].in_features\n",
        "        backbone.classifier = nn.Identity()\n",
        "\n",
        "    # -----------------------------\n",
        "    # YOLO MODELS\n",
        "    # -----------------------------\n",
        "    elif arch in ['yolov11', 'yolov12']:\n",
        "        if load_weights:\n",
        "            model = YOLO(model_paths[arch])\n",
        "        else:\n",
        "            model = YOLO(f\"{arch}.yaml\")\n",
        "\n",
        "        # YOLO backbone feature dimension (example: 1024)\n",
        "        feature_dim = 1024  # adjust based on YOLO version\n",
        "\n",
        "        if use_lstm:\n",
        "            return CNN_LSTM_BiomassEstimator(\n",
        "                backbone=model.model.backbone,\n",
        "                feature_dim=feature_dim,\n",
        "                hidden_dim=hidden_dim,\n",
        "                num_layers=num_layers,\n",
        "                num_targets=num_targets\n",
        "            )\n",
        "        else:\n",
        "            return model\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported architecture: {arch}\")\n",
        "\n",
        "    # -----------------------------\n",
        "    # APPLY LSTM OR STANDARD HEAD\n",
        "    # -----------------------------\n",
        "    if use_lstm:\n",
        "        model = CNN_LSTM_BiomassEstimator(\n",
        "            backbone=backbone,\n",
        "            feature_dim=in_features,\n",
        "            hidden_dim=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            num_targets=num_targets\n",
        "        )\n",
        "    else:\n",
        "        model = MultiTargetWrapper(backbone, in_features, num_targets=num_targets)\n",
        "\n",
        "    # -----------------------------\n",
        "    # LOAD WEIGHTS IF REQUESTED\n",
        "    # -----------------------------\n",
        "    if load_weights and arch not in ['yolov11', 'yolov12']:\n",
        "        state = torch.load(model_paths[arch], map_location=device)\n",
        "        model.load_state_dict(state, strict=True)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "I8OCOOSZaF5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modified the above to include yolos\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "#from ultralytics import YOLO   # for YOLOv8, v9, v11, v12 and above\n",
        "\n",
        "model_paths = {\n",
        "    'mobilenet_v2': \"/content/drive/MyDrive/csiro/mobilenet_v2.pth\",\n",
        "    'googlenet': \"/content/drive/MyDrive/csiro/googlenet.pth\",\n",
        "    'alexnet': \"/content/drive/MyDrive/csiro/alexnet.pth\",\n",
        "    'resnet50': \"/content/drive/MyDrive/csiro/resnet50.pth\",\n",
        "    'convnext_tiny': \"/content/drive/MyDrive/csiro/convnext_tiny.pth\",\n",
        "    'efficientnet_b0': \"/content/drive/MyDrive/csiro/efficientnet_b0.pth\",\n",
        "    'yolov11': \"/content/drive/MyDrive/csiro/yolov11.pt\",\n",
        "    'yolov12': \"/content/drive/MyDrive/csiro/yolov12.pt\"\n",
        "}\n",
        "\n",
        "\n",
        "def build_model1(arch, num_targets=5, load_weights=False, device='cpu'):\n",
        "    if arch == 'mobilenet_v2':\n",
        "        backbone = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
        "        in_features = backbone.classifier[1].in_features\n",
        "        backbone.classifier = nn.Identity()\n",
        "        model = MultiTargetWrapper(backbone, in_features, num_targets=num_targets)\n",
        "    else:\n",
        "        model = MultiTargetWrapper(backbone, in_features, num_targets=num_targets)\n",
        "\n",
        "\n",
        "    elif arch == 'googlenet':\n",
        "        backbone = models.googlenet(weights=None, aux_logits=False)\n",
        "        in_features = backbone.fc.in_features\n",
        "        backbone.fc = nn.Identity()\n",
        "        model = MultiTargetWrapper(backbone, in_features, num_targets=num_targets)\n",
        "\n",
        "    elif arch == 'alexnet':\n",
        "        backbone = models.alexnet(weights=None)\n",
        "        in_features = 9216\n",
        "        backbone.classifier = nn.Sequential(nn.Flatten())\n",
        "        model = MultiTargetWrapper(backbone, in_features, num_targets=num_targets)\n",
        "\n",
        "    elif arch == 'resnet50':\n",
        "        backbone = models.resnet50(weights=None)\n",
        "        in_features = backbone.fc.in_features\n",
        "        backbone.fc = nn.Identity()\n",
        "        model = MultiTargetWrapper(backbone, in_features, num_targets=num_targets)\n",
        "\n",
        "    elif arch == \"convnext_tiny\":\n",
        "        backbone = models.convnext_tiny(weights=None)\n",
        "        in_features = backbone.classifier[2].in_features\n",
        "        backbone.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        model = MultiTargetWrapper(backbone, in_features, num_targets=num_targets)\n",
        "\n",
        "    elif arch == 'efficientnet_b0':\n",
        "        backbone = models.efficientnet_b0(weights=None)\n",
        "        in_features = backbone.classifier[1].in_features\n",
        "        backbone.classifier = nn.Identity()\n",
        "        model = MultiTargetWrapper(backbone, in_features, num_targets=num_targets)\n",
        "\n",
        "    elif arch in ['yolov11', 'yolov12']:\n",
        "        # YOLO models are detection networks, not classification backbones\n",
        "        if load_weights:\n",
        "            path = model_paths.get(arch)\n",
        "            if path:\n",
        "                model = YOLO(path)  # load pretrained weights\n",
        "            else:\n",
        "                raise FileNotFoundError(f\"No path found for architecture: {arch}\")\n",
        "        else:\n",
        "            # Train from scratch using YAML config\n",
        "            model = YOLO(f\"{arch}.yaml\")\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported architecture: {arch}\")\n",
        "\n",
        "    if load_weights and arch not in ['yolov11', 'yolov12']:\n",
        "        path = model_paths.get(arch)\n",
        "        if path:\n",
        "            state = torch.load(path, map_location=device)\n",
        "            model.load_state_dict(state, strict=True)\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"No path found for architecture: {arch}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Mmj4Oc3oxwml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/csiro/csiro-biomass/test.csv\")\n",
        "\n",
        "# Pivot so each image has one row with 5 targets\n",
        "wide_df = df.pivot(index=\"image_path\", columns=\"target_name\", values=\"sample_id\")\n",
        "\n",
        "# If you have actual numeric biomass values in another column (say \"value\"),\n",
        "# replace `sample_id` with that column instead.\n",
        "# Example:\n",
        "# wide_df = df.pivot(index=\"image_path\", columns=\"target_name\", values=\"value\")\n",
        "\n",
        "wide_df.reset_index(inplace=True)\n",
        "print(wide_df.head())\n"
      ],
      "metadata": {
        "id": "fCiVKLbHf49K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Test transformations\n",
        "\n",
        "class PastureDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        df = pd.read_csv(csv_file)\n",
        "        self.image_paths = df[\"image_path\"].unique()\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image  # only the image\n",
        "\n",
        "def predict_model(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:   # batch is a dict\n",
        "            images = batch.to(device)\n",
        "            outputs = model(images)\n",
        "            preds.extend(outputs.cpu().numpy())\n",
        "\n",
        "    return preds\n",
        "\n",
        "\n",
        "results = {}\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ✅ Correct dataset instantiation\n",
        "test_dataset = PastureDataset(\n",
        "    \"/content/drive/MyDrive/csiro/csiro-biomass/test.csv\",\n",
        "    transform=test_transform\n",
        "\n",
        ")\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
        "for arch, path in model_paths.items():\n",
        "    print(f\"\\nPredicting with {arch}...\")\n",
        "    model = build_model(arch, num_targets=5, load_weights=True, device=device)\n",
        "    preds = predict_model(model, test_loader, device)\n",
        "    results[arch] = preds\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/csiro/csiro-biomass/test.csv\")\n",
        "combined = pd.DataFrame({\"image_path\": df[\"image_path\"].unique()})\n",
        "for arch, preds in results.items():\n",
        "    df = pd.DataFrame(preds, columns=[\n",
        "        f\"{arch}_Dry_Clover_g\", f\"{arch}_Dry_Dead_g\",\n",
        "        f\"{arch}_Dry_Green_g\", f\"{arch}_Dry_Total_g\", f\"{arch}_GDM_g\"\n",
        "    ])\n",
        "    combined = pd.concat([combined, df], axis=1)\n",
        "\n",
        "print(combined.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "MJBCHB-UjzUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "veg_types = [\"Dry_Clover_g\", \"Dry_Dead_g\", \"Dry_Green_g\", \"Dry_Total_g\", \"GDM_g\"]\n",
        "\n",
        "records = []\n",
        "for img_path, pred in zip(test_dataset.image_paths, preds):\n",
        "    for veg, value in zip(veg_types, pred):\n",
        "        records.append({\"image_path\": img_path, \"vegetation\": veg, \"prediction\": value})\n",
        "\n",
        "pred_df = pd.DataFrame(records)\n"
      ],
      "metadata": {
        "id": "WLf5jyBnLuIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = torch.load(\"/content/drive/MyDrive/csiro/mobilenet_v2.pth\", map_location=\"cpu\")\n",
        "print([k for k in state.keys() if \"heads\" in k or \"shared_features\" in k])\n"
      ],
      "metadata": {
        "id": "lT9HHgQb5Ril"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import itertools\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Known class names from your CSV\n",
        "CLASS_NAMES = [\"Dry_Clover_g\", \"Dry_Dead_g\", \"Dry_Green_g\", \"Dry_Total_g\", \"GDM_g\"]\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    mae_sum, mse_sum, n = 0.0, 0.0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            images = batch['image'].to(device)\n",
        "            targets = batch['targets'].to(device).float()\n",
        "            outputs = model(images)\n",
        "\n",
        "            mae_sum += torch.mean(torch.abs(outputs - targets)).item()\n",
        "            mse_sum += torch.mean((outputs - targets) ** 2).item()\n",
        "            n += 1\n",
        "\n",
        "    return {\"MAE\": mae_sum/n, \"RMSE\": (mse_sum/n) ** 0.5}\n",
        "\n",
        "def recover_label_map(model, test_loader, device):\n",
        "    best_acc = -1.0\n",
        "    best_mapping = None\n",
        "\n",
        "    # Try all permutations of indices 0..4 assigned to the class names\n",
        "    for perm in itertools.permutations(range(len(CLASS_NAMES))):\n",
        "        candidate = {cls: idx for cls, idx in zip(CLASS_NAMES, perm)}\n",
        "        acc = evaluate_with_mapping(model, test_loader, candidate, device)\n",
        "        if acc > best_acc:\n",
        "            best_acc, best_mapping = acc, candidate\n",
        "\n",
        "    return best_mapping, best_acc\n",
        "\n",
        "# Example usage with one architecture (do for the most stable model first)\n",
        "print(\"\\nRecovering label_map using mobilenet_v2...\")\n",
        "model = build_model('mobilenet_v2', num_targets=5, load_weights=True, device=device)\n",
        "recovered_map, recovered_acc = recover_label_map(model, test_loader, device)\n",
        "print(\"Recovered mapping:\", recovered_map)\n",
        "print(f\"Accuracy with recovered mapping: {recovered_acc:.2%}\")\n"
      ],
      "metadata": {
        "id": "UtbaqCBtvMkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "# Image preprocessing\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),   # resize to match backbone input\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Train dataset\n",
        "train_dataset = PastureDataset(\n",
        "    csv_file=\"/content/drive/MyDrive/csiro/csiro-biomass/train.csv\",\n",
        "    image_dir=\"/content/drive/MyDrive/csiro/csiro-biomass/train\",\n",
        "    transform=train_transforms,\n",
        "    is_test=False\n",
        ")\n",
        "\n",
        "# Test dataset\n",
        "test_dataset = PastureDataset(\n",
        "    csv_file=\"/content/drive/MyDrive/csiro/csiro-biomass/test.csv\",\n",
        "    image_dir=\"/content/drive/MyDrive/csiro/csiro-biomass/test\",\n",
        "    transform=test_transforms,\n",
        "    is_test=True\n",
        ")\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)'''\n"
      ],
      "metadata": {
        "id": "6SK8zgALaxfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#modified codes of the above\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. Train/Validation Split\n",
        "# ---------------------------------------------------------\n",
        "full_df = pd.read_csv(\"/content/drive/MyDrive/csiro/csiro-biomass/train.csv\")\n",
        "\n",
        "train_df, val_df = train_test_split(full_df, test_size=0.15, random_state=42)\n",
        "\n",
        "train_df.to_csv(\"train_split.csv\", index=False)\n",
        "val_df.to_csv(\"val_split.csv\", index=False)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. Image preprocessing (KEEPING 384×384)\n",
        "# ---------------------------------------------------------\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),     # ✅ keep original competition size\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ColorJitter(0.1, 0.1, 0.1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),     # ✅ keep original size\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. Datasets (log1p enabled)\n",
        "# ---------------------------------------------------------\n",
        "train_dataset = PastureDataset(\n",
        "    csv_file=\"train_split.csv\",\n",
        "    image_dir=\"/content/drive/MyDrive/csiro/csiro-biomass/train\",\n",
        "    transform=train_transforms,\n",
        "    is_test=False,\n",
        "    apply_log=True\n",
        ")\n",
        "\n",
        "val_dataset = PastureDataset(\n",
        "    csv_file=\"val_split.csv\",\n",
        "    image_dir=\"/content/drive/MyDrive/csiro/csiro-biomass/train\",\n",
        "    transform=test_transforms,\n",
        "    is_test=False,\n",
        "    apply_log=True\n",
        ")\n",
        "\n",
        "test_dataset = PastureDataset(\n",
        "    csv_file=\"/content/drive/MyDrive/csiro/csiro-biomass/test.csv\",\n",
        "    image_dir=\"/content/drive/MyDrive/csiro/csiro-biomass/test\",\n",
        "    transform=test_transforms,\n",
        "    is_test=True,\n",
        "    apply_log=False\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. DataLoaders\n",
        "# ---------------------------------------------------------\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "id": "qPedX4BDXcs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_backbone_output_dim(backbone):\n",
        "    dummy = torch.randn(1, 3, 384, 384)   # standard input size\n",
        "    with torch.no_grad():\n",
        "        out = backbone(dummy)\n",
        "        if out.ndim > 2:                  # flatten if conv features\n",
        "            out = torch.flatten(out, 1)\n",
        "    return out.shape[1]\n",
        "def build_model(arch, num_targets=5):\n",
        "    if arch == 'mobilenet_v2':\n",
        "        backbone = models.mobilenet_v2(weights=None)\n",
        "        in_features = backbone.classifier[1].in_features\n",
        "        backbone.classifier = nn.Identity()\n",
        "\n",
        "    elif arch == 'googlenet':\n",
        "        backbone = models.googlenet(weights=None, aux_logits=False)\n",
        "        in_features = backbone.fc.in_features\n",
        "        backbone.fc = nn.Identity()\n",
        "\n",
        "    elif arch == 'alexnet':\n",
        "        backbone = models.alexnet(weights=None)\n",
        "        backbone.classifier = nn.Identity()\n",
        "        in_features = 9216  # correct feature size\n",
        "    elif arch == 'resnet50':\n",
        "        backbone = models.resnet50(weights=None)\n",
        "        in_features = backbone.fc.in_features\n",
        "        backbone.fc = nn.Identity()\n",
        "\n",
        "    elif arch == 'convnext_tiny':\n",
        "        backbone = models.convnext_tiny(weights=None)\n",
        "        in_features = backbone.classifier[2].in_features\n",
        "        backbone.classifier = nn.Identity()\n",
        "\n",
        "    elif arch == 'efficientnet_b0':\n",
        "        backbone = models.efficientnet_b0(weights=None)\n",
        "        in_features = backbone.classifier[1].in_features\n",
        "        backbone.classifier = nn.Identity()\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported architecture: {arch}\")\n",
        "\n",
        "    in_features = get_backbone_output_dim(backbone)\n",
        "    # Shared regression head\n",
        "    shared_features = nn.Sequential(\n",
        "        nn.Linear(in_features, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    heads = nn.ModuleList([nn.Linear(256, 1) for _ in range(num_targets)])\n",
        "\n",
        "    return MultiTargetWrapper(backbone, in_features, num_targets=5)\n",
        "\n"
      ],
      "metadata": {
        "id": "Uin4vNHdbOMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import torch.optim as optim\n",
        "def eval_r2(model, val_loader, device):\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            images = batch['image'].to(device)\n",
        "            y = batch['targets'].numpy()\n",
        "            out = model(images).cpu().numpy()\n",
        "            preds.append(out)\n",
        "            targets.append(y)\n",
        "    preds = np.vstack(preds)\n",
        "    targets = np.vstack(targets)\n",
        "    return [r2_score(targets[:,i], preds[:,i]) for i in range(5)]\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, device, num_epochs=10, lr=1e-4):\n",
        "    #criterion = nn.MSELoss()\n",
        "    weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5], device=device)\n",
        "    def weighted_mse(pred, target):\n",
        "        return ((pred - target)**2 * weights).mean()\n",
        "    criterion = weighted_mse\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            images = batch['image'].to(device)\n",
        "            targets = batch['targets'].to(device).float()  # continuous values\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)  # (batch, 5)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, MSE Loss: {avg_loss:.4f}\")\n",
        "    print(eval_r2(model, val_loader, device))\n",
        "    return model'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "muGKKWK_bPav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#modified above codes\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def eval_r2(model, val_loader, device):\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            images = batch['image'].to(device)\n",
        "            y = batch['targets'].numpy()\n",
        "            out = model(images).cpu().numpy()\n",
        "            preds.append(out)\n",
        "            targets.append(y)\n",
        "    preds = np.vstack(preds)\n",
        "    targets = np.vstack(targets)\n",
        "    return [r2_score(targets[:,i], preds[:,i]) for i in range(5)]\n",
        "def train_model(model, train_loader, val_loader, device, num_epochs=30, lr=7e-8):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            images = batch['image'].to(device)\n",
        "            targets = batch['targets'].to(device).float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, MSE Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # ✅ Evaluate R²\n",
        "        r2 = eval_r2(model, val_loader, device)\n",
        "        print(\"Validation R²:\", r2)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "TKYqp9zoXwfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "architectures = [\n",
        "   # 'efficientnet_b0',\n",
        "   'mobilenet_v2',\n",
        "   # 'googlenet',\n",
        "   # 'alexnet',\n",
        "    #'resnet50',\n",
        "   # 'convnext_tiny'\n",
        "]\n",
        "trained_models = {}\n",
        "\n",
        "for arch in architectures:\n",
        "    print(f\"\\nTraining {arch} from scratch...\")\n",
        "    model = build_model(arch, num_targets=5,use_lstm=True)\n",
        "    #trained_model = train_model(model, train_loader, device, num_epochs=20, lr=1e-4)\n",
        "    trained_model = train_model(model, train_loader, val_loader, device, num_epochs=50, lr=5e-7)\n",
        "    trained_models[arch] = trained_model\n",
        "    # Save weights\n",
        "    torch.save(trained_model.state_dict(), f\"/content/drive/MyDrive/csiro/{arch}_lstm_50_.pth\")\n"
      ],
      "metadata": {
        "id": "x-TzQCPGbTFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resnet50 + LSTM\n",
        "class ResNetLSTM(nn.Module):\n",
        "    def __init__(self, num_targets=5, hidden_size=256, num_layers=1, bidirectional=False):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet50(weights=None)\n",
        "        feat_dim = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Identity()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=feat_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        lstm_out_dim = hidden_size * (2 if bidirectional else 1)\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(lstm_out_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_targets)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len, C, H, W)\n",
        "        b, t, c, h, w = x.shape\n",
        "        x = x.view(b * t, c, h, w)\n",
        "        feats = self.backbone(x)         # (b*t, feat_dim)\n",
        "        if feats.dim() > 2:\n",
        "            feats = torch.flatten(feats, 1)\n",
        "        feats = feats.view(b, t, -1)\n",
        "        lstm_out, _ = self.lstm(feats)\n",
        "        last_out = lstm_out[:, -1, :]\n",
        "        out = self.head(last_out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "kEQbnb78grlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mobilenet+LSTM\n",
        "\n",
        "import torchvision.models as models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "class MobileNetLSTM(nn.Module):\n",
        "    def __init__(self, num_targets=5, hidden_size=256, num_layers=1, bidirectional=False):\n",
        "        super().__init__()\n",
        "        self.backbone = models.mobilenet_v2(weights=None)   # start from scratch\n",
        "        feat_dim = self.backbone.classifier[1].in_features\n",
        "        self.backbone.classifier = nn.Identity()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=feat_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        lstm_out_dim = hidden_size * (2 if bidirectional else 1)\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(lstm_out_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_targets)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Expecting (batch, seq_len, C, H, W)\n",
        "        if x.dim() == 4:\n",
        "            # If dataset gives single images, add seq_len=1\n",
        "            x = x.unsqueeze(1)\n",
        "\n",
        "        b, t, c, h, w = x.shape\n",
        "        x = x.view(b * t, c, h, w)\n",
        "        feats = self.backbone(x)\n",
        "        if feats.dim() > 2:\n",
        "            feats = torch.flatten(feats, 1)\n",
        "\n",
        "        feats = feats.view(b, t, -1)\n",
        "        lstm_out, _ = self.lstm(feats)\n",
        "        last_out = lstm_out[:, -1, :]\n",
        "        out = self.head(last_out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "XvCvOYQHlJ6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize model\n",
        "model = MobileNetLSTM(num_targets=5, hidden_size=256, num_layers=1, bidirectional=False)\n",
        "\n",
        "# Train model\n",
        "trained_model = train_model(model, train_loader, val_loader, device, num_epochs=30, lr=1e-4)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Save the trained model\n",
        "# ---------------------------------------------------------\n",
        "# Option 1: Save only the state_dict (recommended)\n",
        "torch.save(trained_model.state_dict(), \"mobilenet_lstm_model.pth\")\n",
        "\n",
        "# Option 2: Save the entire model (less portable)\n",
        "# torch.save(trained_model, \"mobilenet_lstm_full.pth\")\n"
      ],
      "metadata": {
        "id": "iujWNVaXlNnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#joint MobileNetV2 + ResNet50 model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class DualBackboneMultiTarget(nn.Module):\n",
        "    def __init__(self, num_targets=5):\n",
        "        super().__init__()\n",
        "\n",
        "        # MobileNetV2 backbone\n",
        "        self.mobilenet = models.mobilenet_v2(weights=None)\n",
        "        mobilenet_features = self.mobilenet.classifier[1].in_features\n",
        "        self.mobilenet.classifier = nn.Identity()\n",
        "\n",
        "        # ResNet50 backbone\n",
        "        self.resnet = models.resnet50(weights=None)\n",
        "        resnet_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Identity()\n",
        "\n",
        "        # Total fused feature size\n",
        "        fused_in_features = mobilenet_features + resnet_features\n",
        "\n",
        "        # Shared MLP (similar to your MultiTargetWrapper)\n",
        "        self.shared_features = nn.Sequential(\n",
        "            nn.Linear(fused_in_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        # Multi‑target heads\n",
        "        self.heads = nn.ModuleList([nn.Linear(256, 1) for _ in range(num_targets)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat_m = self.mobilenet(x)  # (batch, mobilenet_features)\n",
        "        feat_r = self.resnet(x)     # (batch, resnet_features)\n",
        "\n",
        "        # If any is not flattened (should already be), ensure flatten:\n",
        "        if feat_m.dim() > 2:\n",
        "            feat_m = torch.flatten(feat_m, 1)\n",
        "        if feat_r.dim() > 2:\n",
        "            feat_r = torch.flatten(feat_r, 1)\n",
        "\n",
        "        fused = torch.cat([feat_m, feat_r], dim=1)  # (batch, fused_in_features)\n",
        "        shared = self.shared_features(fused)\n",
        "        outputs = [head(shared) for head in self.heads]\n",
        "        return torch.cat(outputs, dim=1)  # (batch, num_targets)\n",
        "\n",
        "# Build and optionally load individual backbone weights\n",
        "def build_dual_model(mobilenet_path=None, resnet_path=None, device='cpu', num_targets=5):\n",
        "    model = DualBackboneMultiTarget(num_targets=num_targets)\n",
        "\n",
        "    # Optional: initialize each backbone with your pre‑trained weights\n",
        "    if mobilenet_path is not None:\n",
        "        single_mobilenet = build_model('mobilenet_v2', num_targets=num_targets, load_weights=True, device=device)\n",
        "        model.mobilenet.load_state_dict(single_mobilenet.backbone.state_dict(), strict=False)\n",
        "\n",
        "    if resnet_path is not None:\n",
        "        single_resnet = build_model('resnet50', num_targets=num_targets, load_weights=True, device=device)\n",
        "        model.resnet.load_state_dict(single_resnet.backbone.state_dict(), strict=False)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "dual_model = build_dual_model(\n",
        "    mobilenet_path=\"/content/drive/MyDrive/csiro/mobilenet_v2.pth\",\n",
        "    resnet_path=\"/content/drive/MyDrive/csiro/resnet50.pth\",\n",
        "    device=device,\n",
        "    num_targets=5\n",
        ").to(device)\n",
        "\n",
        "def train_model_regression(model, train_loader, device, num_epochs=10, lr=1e-4):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            images = batch['image'].to(device)\n",
        "            targets = batch['targets'].to(device).float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, MSE Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train the dual model\n",
        "dual_model = train_model_regression(dual_model, train_loader, device, num_epochs=30, lr=1e-4)\n",
        "torch.save(dual_model.state_dict(), \"/content/drive/MyDrive/csiro/mobilenet_resnet_dual.pth\")\n"
      ],
      "metadata": {
        "id": "ZKhpkoLdhOEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading models after training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#/content/drive/MyDrive/csiro/efficientnet_b0.pth\n",
        "architectures = [\n",
        "    'efficientnet_b0',\n",
        "    'mobilenet_v2',\n",
        "    'googlenet',\n",
        "    'alexnet',\n",
        "    'resnet50',\n",
        "    'convnext_tiny'\n",
        "]\n",
        "import torch\n",
        "\n",
        "loaded_models = {}\n",
        "\n",
        "for arch in architectures:\n",
        "    print(f\"Loading {arch}...\")\n",
        "    model = build_model(arch, num_targets=5)   # must match training setup\n",
        "    model.load_state_dict(torch.load(f\"/content/drive/MyDrive/csiro/{arch}.pth\", map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    loaded_models[arch] = model\n"
      ],
      "metadata": {
        "id": "gmr83SRn76NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to use with testing only\n",
        "class PastureDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return {\n",
        "            \"image\": image,\n",
        "            \"sample_id\": row[\"sample_id\"]\n",
        "        }"
      ],
      "metadata": {
        "id": "NmEHc_zrCVYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing models after training\n",
        "import pandas as pd\n",
        "\n",
        "# Target names in fixed order (must match training order)\n",
        "target_names = [\"Dry_Clover_g\", \"Dry_Dead_g\", \"Dry_Green_g\", \"Dry_Total_g\", \"GDM_g\"]\n",
        "\n",
        "def generate_submission(model, test_loader, device, output_csv=\"submission.csv\"):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            images = batch['image'].to(device)\n",
        "            outputs = model(images)  # shape (batch, 5)\n",
        "            outputs = outputs.cpu().numpy()\n",
        "\n",
        "            # Each row in test.csv has a sample_id like IDxxxx__TargetName\n",
        "            sample_ids = batch['sample_id']\n",
        "\n",
        "            for i, sid in enumerate(sample_ids):\n",
        "                target_name = sid.split(\"__\")[1]\n",
        "                idx = target_names.index(target_name)\n",
        "\n",
        "                predictions.append({\n",
        "                    \"sample_id\": sid,\n",
        "                    \"target\": float(outputs[i, idx])\n",
        "                })\n",
        "\n",
        "    df = pd.DataFrame(predictions)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"Saved predictions to {output_csv}\")\n"
      ],
      "metadata": {
        "id": "ZtJlqU6z6jRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Looping over all models\n",
        "# Define transforms\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset and loader\n",
        "test_dataset = PastureDataset(\n",
        "    \"/content/drive/MyDrive/csiro/csiro-biomass/test.csv\",\n",
        "    transform=test_transform\n",
        ")\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "# Run submission generation\n",
        "for arch, model in loaded_models.items():\n",
        "    print(f\"Generating submission for {arch}...\")\n",
        "    generate_submission(model, test_loader, device,\n",
        "                        output_csv=f\"/content/drive/MyDrive/csiro/{arch}_submission.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9A5ZSw6V8dcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Right after you create train_loader\n",
        "batch = next(iter(train_loader))\n",
        "print(\"Sample targets:\", batch['targets'][:10])\n",
        "print(\"Unique values:\", torch.unique(batch['targets']))\n"
      ],
      "metadata": {
        "id": "QBAcPixVHamU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Data Analysis and Feature Engineering\n",
        "def additional_analysis():\n",
        "    \"\"\"Additional data analysis for insights\"\"\"\n",
        "\n",
        "    train_df = pd.read_csv('/content/drive/MyDrive/csiro/csiro-biomass/train.csv')\n",
        "\n",
        "    # Analyze by state\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for i, target in enumerate(['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g'], 1):\n",
        "        plt.subplot(2, 3, i)\n",
        "        target_data = train_df[train_df['target_name'] == target]\n",
        "        sns.boxplot(data=target_data, x='State', y='target')\n",
        "        plt.title(f'{target} by State')\n",
        "        plt.xticks(rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Analyze relationship with NDVI and Height\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    targets = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
        "\n",
        "    for i, target in enumerate(targets):\n",
        "        target_data = train_df[train_df['target_name'] == target]\n",
        "        axes[i].scatter(target_data['Pre_GSHH_NDVI'], target_data['target'], alpha=0.5)\n",
        "        axes[i].set_xlabel('NDVI')\n",
        "        axes[i].set_ylabel(target)\n",
        "        axes[i].set_title(f'{target} vs NDVI')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run additional analysis\n",
        "additional_analysis()"
      ],
      "metadata": {
        "id": "JwGjIBtZ4LiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Key Features of This Solution:\n",
        "Multi-Target Architecture: Single model predicting all 5 biomass components\n",
        "\n",
        "Data Augmentation: Improved generalization with image transformations\n",
        "\n",
        "Transfer Learning: Using pre-trained EfficientNet backbone\n",
        "\n",
        "Comprehensive Validation: Proper train/validation split and monitoring\n",
        "\n",
        "Robust Predictions: Handling edge cases and ensuring non-negative values\n",
        "\n",
        "Extensible Design: Easy to modify for ensemble approaches\n",
        "\n",
        "Next Steps for Improvement:\n",
        "Hyperparameter Tuning: Optimize learning rates, architecture\n",
        "\n",
        "Ensemble Methods: Combine multiple models\n",
        "\n",
        "Additional Features: Incorporate NDVI and height data if available\n",
        "\n",
        "Advanced Augmentation: More sophisticated image transformations\n",
        "\n",
        "Cross-Validation: More robust validation strategy\n",
        "\n",
        "This solution provides a solid foundation for predicting pasture biomass components and can be further optimized based on validation performance.'''"
      ],
      "metadata": {
        "id": "vtaTGOfB4axE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}